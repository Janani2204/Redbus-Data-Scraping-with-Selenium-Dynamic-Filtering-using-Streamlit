{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d6a36d-3443-4fa7-92b4-76d7b208d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\kisho\\anaconda3\\lib\\site-packages (4.23.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from selenium) (2024.6.2)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\kisho\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f8718d-dcad-4617-af87-9293c68a8b4f",
   "metadata": {},
   "source": [
    "# ASRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d358d0d2-5b89-4f45-9a65-3557247ec30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'View Buses' button not found for route Kakinada to Visakhapatnam. Extracting available data.\n",
      "'View Buses' button not found for route Madanapalli to Bangalore. Extracting available data.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the URL in the browser\n",
    "driver.get('https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile')\n",
    "# URL for scraping the government bus data. Paste the link as per other government bus services to scrape.\n",
    "driver.maximize_window()\n",
    "time.sleep(10)\n",
    "\n",
    "# Function to extract routes from the current page\n",
    "def extract_routes():\n",
    "    elements = driver.find_elements(By.XPATH, \"//a[@class='route']\")\n",
    "    return [{'text': element.text, 'link': element.get_attribute('href')} for element in elements]\n",
    "\n",
    "# Initialize routes list\n",
    "all_routes = []\n",
    "\n",
    "# Try to navigate through pages and capture routes\n",
    "page_xpaths = [\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[2]',  # Page 2\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[3]',  # Page 3\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[4]',  # Page 4\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[5]'   # Page 5\n",
    "]\n",
    "\n",
    "# Extract routes from the first page\n",
    "all_routes.extend(extract_routes())\n",
    "\n",
    "# Loop through each page's XPath and extract routes\n",
    "for page_xpath in page_xpaths:\n",
    "    try:\n",
    "        # Wait for the element to be clickable\n",
    "        element = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, page_xpath)))\n",
    "\n",
    "        # Scroll the element into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Click the element using JavaScript\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Extract routes from the current page\n",
    "        all_routes.extend(extract_routes())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not navigate to the next page or extract routes: {e}\")\n",
    "        continue\n",
    "\n",
    "# Prepare the CSV file\n",
    "csv_file_path = 'apsrtc_bus_data.csv'\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Route Name', 'Route Link', 'Bus Name', 'Bus Type', 'Departing Time', 'Duration', 'Reaching Time', 'Star Rating', 'Price', 'Seats Available'])\n",
    "\n",
    "    for route in all_routes:\n",
    "        # Navigate to the route page\n",
    "        driver.get(route['link'])\n",
    "        time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            # Attempt to click on the \"View Buses\" element if it exists\n",
    "            view_buses_xpath = '//*[@id=\"result-section\"]/div[1]/div/div[2]/div/div[4]/div[2]'\n",
    "            view_buses = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, view_buses_xpath)))\n",
    "            view_buses.click()\n",
    "            time.sleep(5)\n",
    "        except TimeoutException:\n",
    "            print(f\"'View Buses' button not found for route {route['text']}. Extracting available data.\")\n",
    "\n",
    "        # Scroll down to the bottom of the page to load all content\n",
    "        SCROLL_PAUSE_TIME = 5\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            # Scroll down to the bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            \n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Extract data after reaching the bottom of the page\n",
    "        def get_elements(xpath):\n",
    "            return [elem.text for elem in driver.find_elements(By.XPATH, xpath)]\n",
    "\n",
    "        busname_xpath = \"//div[@class='travels lh-24 f-bold d-color']\"\n",
    "        bustype_xpath = \"//*[@class='bus-type f-12 m-top-16 l-color evBus']\"\n",
    "        departing_time_xpath = \"//*[@class='dp-time f-19 d-color f-bold']\"\n",
    "        duration_xpath = \"//*[@class='dur l-color lh-24']\"\n",
    "        reaching_time_xpath = \"//*[@class='bp-time f-19 d-color disp-Inline']\"\n",
    "        star_rating_xpath = \"//*[@class='column-six p-right-10 w-10 fl']\"\n",
    "        price_xpath = \"//*[contains(@class, 'fare d-block')]\"\n",
    "        seats_available_xpath = \"//*[@class='column-eight w-15 fl']\"\n",
    "\n",
    "        busnames = get_elements(busname_xpath)\n",
    "        bustypes = get_elements(bustype_xpath)\n",
    "        departing_times = get_elements(departing_time_xpath)\n",
    "        durations = get_elements(duration_xpath)\n",
    "        reaching_times = get_elements(reaching_time_xpath)\n",
    "        star_ratings = get_elements(star_rating_xpath)\n",
    "        prices = get_elements(price_xpath)\n",
    "        seats_available = get_elements(seats_available_xpath)\n",
    "\n",
    "        # Define the clean_price function\n",
    "        def clean_price(price_text):\n",
    "            return re.sub(r'[^0-9.]', '', price_text.strip())\n",
    "\n",
    "        # Clean and extend lists\n",
    "        prices = [clean_price(price) for price in prices]\n",
    "\n",
    "        length = max(len(busnames), len(bustypes), len(departing_times), len(durations), len(reaching_times), len(star_ratings), len(prices), len(seats_available))\n",
    "\n",
    "        def extend_list(lst, length):\n",
    "            return lst + ['N/A'] * (length - len(lst))\n",
    "\n",
    "        busnames = extend_list(busnames, length)\n",
    "        bustypes = extend_list(bustypes, length)\n",
    "        departing_times = extend_list(departing_times, length)\n",
    "        durations = extend_list(durations, length)\n",
    "        reaching_times = extend_list(reaching_times, length)\n",
    "        star_ratings = extend_list(star_ratings, length)\n",
    "        prices = extend_list(prices, length)\n",
    "        seats_available = extend_list(seats_available, length)\n",
    "\n",
    "        # Write data to CSV\n",
    "        for i in range(length):\n",
    "            writer.writerow([\n",
    "                route['text'],\n",
    "                route['link'],\n",
    "                busnames[i],\n",
    "                bustypes[i],\n",
    "                departing_times[i],\n",
    "                durations[i],\n",
    "                reaching_times[i],\n",
    "                star_ratings[i],\n",
    "                prices[i],\n",
    "                seats_available[i]\n",
    "            ])\n",
    "\n",
    "        # Go back to the main route list\n",
    "        driver.back()\n",
    "        time.sleep(10) \n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd9cb3-472b-4c5b-ae74-f3dc82bc7304",
   "metadata": {},
   "source": [
    "# Telangana State Road Transport Corporation (TSRTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d935e64f-97c5-46fc-970d-47243a8d77f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not navigate to the next page or extract routes: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6444F9642+30946]\n",
      "\t(No symbol) [0x00007FF6444AE3D9]\n",
      "\t(No symbol) [0x00007FF6443A6FDA]\n",
      "\t(No symbol) [0x00007FF6443F822C]\n",
      "\t(No symbol) [0x00007FF6443F850C]\n",
      "\t(No symbol) [0x00007FF64443DCB7]\n",
      "\t(No symbol) [0x00007FF64441CAAF]\n",
      "\t(No symbol) [0x00007FF64443B041]\n",
      "\t(No symbol) [0x00007FF64441C813]\n",
      "\t(No symbol) [0x00007FF6443EA6E5]\n",
      "\t(No symbol) [0x00007FF6443EB021]\n",
      "\tGetHandleVerifier [0x00007FF64462F84D+1301229]\n",
      "\tGetHandleVerifier [0x00007FF64463BDC7+1351783]\n",
      "\tGetHandleVerifier [0x00007FF644632A13+1313971]\n",
      "\tGetHandleVerifier [0x00007FF64452DD16+245686]\n",
      "\t(No symbol) [0x00007FF6444B759F]\n",
      "\t(No symbol) [0x00007FF6444B3814]\n",
      "\t(No symbol) [0x00007FF6444B39A2]\n",
      "\t(No symbol) [0x00007FF6444AA3FF]\n",
      "\tBaseThreadInitThunk [0x00007FFFB4B0257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFFB5DEAF28+40]\n",
      "\n",
      "Could not navigate to the next page or extract routes: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6444F9642+30946]\n",
      "\t(No symbol) [0x00007FF6444AE3D9]\n",
      "\t(No symbol) [0x00007FF6443A6FDA]\n",
      "\t(No symbol) [0x00007FF6443F822C]\n",
      "\t(No symbol) [0x00007FF6443F850C]\n",
      "\t(No symbol) [0x00007FF64443DCB7]\n",
      "\t(No symbol) [0x00007FF64441CAAF]\n",
      "\t(No symbol) [0x00007FF64443B041]\n",
      "\t(No symbol) [0x00007FF64441C813]\n",
      "\t(No symbol) [0x00007FF6443EA6E5]\n",
      "\t(No symbol) [0x00007FF6443EB021]\n",
      "\tGetHandleVerifier [0x00007FF64462F84D+1301229]\n",
      "\tGetHandleVerifier [0x00007FF64463BDC7+1351783]\n",
      "\tGetHandleVerifier [0x00007FF644632A13+1313971]\n",
      "\tGetHandleVerifier [0x00007FF64452DD16+245686]\n",
      "\t(No symbol) [0x00007FF6444B759F]\n",
      "\t(No symbol) [0x00007FF6444B3814]\n",
      "\t(No symbol) [0x00007FF6444B39A2]\n",
      "\t(No symbol) [0x00007FF6444AA3FF]\n",
      "\tBaseThreadInitThunk [0x00007FFFB4B0257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFFB5DEAF28+40]\n",
      "\n",
      "'View Buses' button not found for route Hyderabad to Srisailam. Extracting available data.\n",
      "'View Buses' button not found for route Hyderabad to Godavarikhani. Extracting available data.\n",
      "'View Buses' button not found for route Hyderabad to Warangal. Extracting available data.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the URL in the browser\n",
    "driver.get('https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile')\n",
    "# URL for scraping the government bus data. Paste the link as per other government bus services to scrape.\n",
    "driver.maximize_window()\n",
    "time.sleep(10)\n",
    "\n",
    "# Function to extract routes from the current page\n",
    "def extract_routes():\n",
    "    elements = driver.find_elements(By.XPATH, \"//a[@class='route']\")\n",
    "    return [{'text': element.text, 'link': element.get_attribute('href')} for element in elements]\n",
    "\n",
    "# Initialize routes list\n",
    "all_routes = []\n",
    "\n",
    "# Try to navigate through pages and capture routes\n",
    "page_xpaths = [\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[2]',  # Page 2\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[3]',  # Page 3\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[4]',  # Page 4\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[5]'   # Page 5\n",
    "]\n",
    "\n",
    "# Extract routes from the first page\n",
    "all_routes.extend(extract_routes())\n",
    "\n",
    "# Loop through each page's XPath and extract routes\n",
    "for page_xpath in page_xpaths:\n",
    "    try:\n",
    "        # Wait for the element to be clickable\n",
    "        element = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, page_xpath)))\n",
    "\n",
    "        # Scroll the element into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Click the element using JavaScript\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Extract routes from the current page\n",
    "        all_routes.extend(extract_routes())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not navigate to the next page or extract routes: {e}\")\n",
    "        continue\n",
    "\n",
    "# Prepare the CSV file\n",
    "csv_file_path = 'tsrtc_bus_data.csv'\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Route Name', 'Route Link', 'Bus Name', 'Bus Type', 'Departing Time', 'Duration', 'Reaching Time', 'Star Rating', 'Price', 'Seats Available'])\n",
    "\n",
    "    for route in all_routes:\n",
    "        # Navigate to the route page\n",
    "        driver.get(route['link'])\n",
    "        time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            # Attempt to click on the \"View Buses\" element if it exists\n",
    "            view_buses_xpath = '//*[@id=\"result-section\"]/div[1]/div/div[2]/div/div[4]/div[2]'\n",
    "            view_buses = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, view_buses_xpath)))\n",
    "            view_buses.click()\n",
    "            time.sleep(5)\n",
    "        except TimeoutException:\n",
    "            print(f\"'View Buses' button not found for route {route['text']}. Extracting available data.\")\n",
    "\n",
    "        # Scroll down to the bottom of the page to load all content\n",
    "        SCROLL_PAUSE_TIME = 5\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            # Scroll down to the bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            \n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Extract data after reaching the bottom of the page\n",
    "        def get_elements(xpath):\n",
    "            return [elem.text for elem in driver.find_elements(By.XPATH, xpath)]\n",
    "\n",
    "        busname_xpath = \"//div[@class='travels lh-24 f-bold d-color']\"\n",
    "        bustype_xpath = \"//*[@class='bus-type f-12 m-top-16 l-color evBus']\"\n",
    "        departing_time_xpath = \"//*[@class='dp-time f-19 d-color f-bold']\"\n",
    "        duration_xpath = \"//*[@class='dur l-color lh-24']\"\n",
    "        reaching_time_xpath = \"//*[@class='bp-time f-19 d-color disp-Inline']\"\n",
    "        star_rating_xpath = \"//*[@class='column-six p-right-10 w-10 fl']\"\n",
    "        price_xpath = \"//*[contains(@class, 'fare d-block')]\"\n",
    "        seats_available_xpath = \"//*[@class='column-eight w-15 fl']\"\n",
    "\n",
    "        busnames = get_elements(busname_xpath)\n",
    "        bustypes = get_elements(bustype_xpath)\n",
    "        departing_times = get_elements(departing_time_xpath)\n",
    "        durations = get_elements(duration_xpath)\n",
    "        reaching_times = get_elements(reaching_time_xpath)\n",
    "        star_ratings = get_elements(star_rating_xpath)\n",
    "        prices = get_elements(price_xpath)\n",
    "        seats_available = get_elements(seats_available_xpath)\n",
    "\n",
    "        # Define the clean_price function\n",
    "        def clean_price(price_text):\n",
    "            return re.sub(r'[^0-9.]', '', price_text.strip())\n",
    "\n",
    "        # Clean and extend lists\n",
    "        prices = [clean_price(price) for price in prices]\n",
    "\n",
    "        length = max(len(busnames), len(bustypes), len(departing_times), len(durations), len(reaching_times), len(star_ratings), len(prices), len(seats_available))\n",
    "\n",
    "        def extend_list(lst, length):\n",
    "            return lst + ['N/A'] * (length - len(lst))\n",
    "\n",
    "        busnames = extend_list(busnames, length)\n",
    "        bustypes = extend_list(bustypes, length)\n",
    "        departing_times = extend_list(departing_times, length)\n",
    "        durations = extend_list(durations, length)\n",
    "        reaching_times = extend_list(reaching_times, length)\n",
    "        star_ratings = extend_list(star_ratings, length)\n",
    "        prices = extend_list(prices, length)\n",
    "        seats_available = extend_list(seats_available, length)\n",
    "\n",
    "        # Write data to CSV\n",
    "        for i in range(length):\n",
    "            writer.writerow([\n",
    "                route['text'],\n",
    "                route['link'],\n",
    "                busnames[i],\n",
    "                bustypes[i],\n",
    "                departing_times[i],\n",
    "                durations[i],\n",
    "                reaching_times[i],\n",
    "                star_ratings[i],\n",
    "                prices[i],\n",
    "                seats_available[i]\n",
    "            ])\n",
    "\n",
    "        # Go back to the main route list\n",
    "        driver.back()\n",
    "        time.sleep(10) \n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff7582-b9e2-4b2f-893e-9ebce1e0ebfe",
   "metadata": {},
   "source": [
    "# West Bengal Transport Corporation WBTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fda5703b-4ab0-403c-9178-112ece7ca710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'View Buses' button not found for route Barasat (West Bengal) to Digha. Extracting available data.\n",
      "'View Buses' button not found for route Bolpur (West Bengal) to Kolkata. Extracting available data.\n",
      "'View Buses' button not found for route Habra to Digha. Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Nandakumar (west bengal). Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Contai (Kanthi). Extracting available data.\n",
      "'View Buses' button not found for route Siliguri to Kolkata. Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Bolpur (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Midnapore. Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Kolaghat. Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Durgapur (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Heria. Extracting available data.\n",
      "'View Buses' button not found for route Haldia to Barasat (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Haldia. Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Burdwan. Extracting available data.\n",
      "'View Buses' button not found for route Durgapur (West Bengal) to Barasat (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Debra. Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Asansol (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Bakkhali. Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Nimtouri. Extracting available data.\n",
      "'View Buses' button not found for route Habra to Kolaghat. Extracting available data.\n",
      "'View Buses' button not found for route Habra to Durgapur (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Barasat (West Bengal) to Mechogram. Extracting available data.\n",
      "'View Buses' button not found for route Habra to Haldia. Extracting available data.\n",
      "'View Buses' button not found for route Habra to Contai (Kanthi). Extracting available data.\n",
      "'View Buses' button not found for route Habra to Midnapore. Extracting available data.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the URL in the browser\n",
    "driver.get('https://www.redbus.in/online-booking/wbtc-ctc/?utm_source=rtchometile')\n",
    "# URL for scraping the government bus data. Paste the link as per other government bus services to scrape.\n",
    "driver.maximize_window()\n",
    "time.sleep(10)\n",
    "\n",
    "# Function to extract routes from the current page\n",
    "def extract_routes():\n",
    "    elements = driver.find_elements(By.XPATH, \"//a[@class='route']\")\n",
    "    return [{'text': element.text, 'link': element.get_attribute('href')} for element in elements]\n",
    "\n",
    "# Initialize routes list\n",
    "all_routes = []\n",
    "\n",
    "# Try to navigate through pages and capture routes\n",
    "page_xpaths = [\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[2]',  # Page 2\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[3]',  # Page 3\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[4]',  # Page 4\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[5]'   # Page 5\n",
    "]\n",
    "\n",
    "# Extract routes from the first page\n",
    "all_routes.extend(extract_routes())\n",
    "\n",
    "# Loop through each page's XPath and extract routes\n",
    "for page_xpath in page_xpaths:\n",
    "    try:\n",
    "        # Wait for the element to be clickable\n",
    "        element = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, page_xpath)))\n",
    "\n",
    "        # Scroll the element into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Click the element using JavaScript\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Extract routes from the current page\n",
    "        all_routes.extend(extract_routes())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not navigate to the next page or extract routes: {e}\")\n",
    "        continue\n",
    "\n",
    "# Prepare the CSV file\n",
    "csv_file_path = 'WBTC_bus_data.csv'\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Route Name', 'Route Link', 'Bus Name', 'Bus Type', 'Departing Time', 'Duration', 'Reaching Time', 'Star Rating', 'Price', 'Seats Available'])\n",
    "\n",
    "    for route in all_routes:\n",
    "        # Navigate to the route page\n",
    "        driver.get(route['link'])\n",
    "        time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            # Attempt to click on the \"View Buses\" element if it exists\n",
    "            view_buses_xpath = '//*[@id=\"result-section\"]/div[1]/div/div[2]/div/div[4]/div[2]'\n",
    "            view_buses = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, view_buses_xpath)))\n",
    "            view_buses.click()\n",
    "            time.sleep(5)\n",
    "        except TimeoutException:\n",
    "            print(f\"'View Buses' button not found for route {route['text']}. Extracting available data.\")\n",
    "\n",
    "        # Scroll down to the bottom of the page to load all content\n",
    "        SCROLL_PAUSE_TIME = 5\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            # Scroll down to the bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            \n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Extract data after reaching the bottom of the page\n",
    "        def get_elements(xpath):\n",
    "            return [elem.text for elem in driver.find_elements(By.XPATH, xpath)]\n",
    "\n",
    "        busname_xpath = \"//div[@class='travels lh-24 f-bold d-color']\"\n",
    "        bustype_xpath = \"//*[@class='bus-type f-12 m-top-16 l-color evBus']\"\n",
    "        departing_time_xpath = \"//*[@class='dp-time f-19 d-color f-bold']\"\n",
    "        duration_xpath = \"//*[@class='dur l-color lh-24']\"\n",
    "        reaching_time_xpath = \"//*[@class='bp-time f-19 d-color disp-Inline']\"\n",
    "        star_rating_xpath = \"//*[@class='column-six p-right-10 w-10 fl']\"\n",
    "        price_xpath = \"//*[contains(@class, 'fare d-block')]\"\n",
    "        seats_available_xpath = \"//*[@class='column-eight w-15 fl']\"\n",
    "\n",
    "        busnames = get_elements(busname_xpath)\n",
    "        bustypes = get_elements(bustype_xpath)\n",
    "        departing_times = get_elements(departing_time_xpath)\n",
    "        durations = get_elements(duration_xpath)\n",
    "        reaching_times = get_elements(reaching_time_xpath)\n",
    "        star_ratings = get_elements(star_rating_xpath)\n",
    "        prices = get_elements(price_xpath)\n",
    "        seats_available = get_elements(seats_available_xpath)\n",
    "\n",
    "        # Define the clean_price function\n",
    "        def clean_price(price_text):\n",
    "            return re.sub(r'[^0-9.]', '', price_text.strip())\n",
    "\n",
    "        # Clean and extend lists\n",
    "        prices = [clean_price(price) for price in prices]\n",
    "\n",
    "        length = max(len(busnames), len(bustypes), len(departing_times), len(durations), len(reaching_times), len(star_ratings), len(prices), len(seats_available))\n",
    "\n",
    "        def extend_list(lst, length):\n",
    "            return lst + ['N/A'] * (length - len(lst))\n",
    "\n",
    "        busnames = extend_list(busnames, length)\n",
    "        bustypes = extend_list(bustypes, length)\n",
    "        departing_times = extend_list(departing_times, length)\n",
    "        durations = extend_list(durations, length)\n",
    "        reaching_times = extend_list(reaching_times, length)\n",
    "        star_ratings = extend_list(star_ratings, length)\n",
    "        prices = extend_list(prices, length)\n",
    "        seats_available = extend_list(seats_available, length)\n",
    "\n",
    "        # Write data to CSV\n",
    "        for i in range(length):\n",
    "            writer.writerow([\n",
    "                route['text'],\n",
    "                route['link'],\n",
    "                busnames[i],\n",
    "                bustypes[i],\n",
    "                departing_times[i],\n",
    "                durations[i],\n",
    "                reaching_times[i],\n",
    "                star_ratings[i],\n",
    "                prices[i],\n",
    "                seats_available[i]\n",
    "            ])\n",
    "\n",
    "        # Go back to the main route list\n",
    "        driver.back()\n",
    "        time.sleep(10) \n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04317358-8966-4c62-8fbb-f93ae4ce3de3",
   "metadata": {},
   "source": [
    "# NORTH BENGAL STATE TRANSPORT CORPORATION(NBSTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e82f43c6-0131-4ed6-ba23-f175f8da83cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'View Buses' button not found for route Siliguri to Darjeeling. Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Cooch Behar (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Berhampore (West Bengal) to Cooch Behar (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Cooch Behar (West Bengal) to Kolkata. Extracting available data.\n",
      "'View Buses' button not found for route Berhampore (West Bengal) to Siliguri. Extracting available data.\n",
      "'View Buses' button not found for route Siliguri to Berhampore (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Gangarampur. Extracting available data.\n",
      "'View Buses' button not found for route Siliguri to Kalimpong. Extracting available data.\n",
      "'View Buses' button not found for route Cooch Behar (West Bengal) to Malda. Extracting available data.\n",
      "'View Buses' button not found for route Malda to Cooch Behar (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Jalpaiguri. Extracting available data.\n",
      "'View Buses' button not found for route Falakata (west bengal) to Berhampore (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Falakata (west bengal). Extracting available data.\n",
      "'View Buses' button not found for route Cooch Behar (West Bengal) to Raiganj. Extracting available data.\n",
      "'View Buses' button not found for route Siliguri to Cooch Behar (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Raiganj to Krishnanagar (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Raiganj to Siliguri. Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Buniadpur. Extracting available data.\n",
      "'View Buses' button not found for route Gangarampur to Kolkata. Extracting available data.\n",
      "'View Buses' button not found for route Siliguri to Ranaghat. Extracting available data.\n",
      "'View Buses' button not found for route Siliguri to Krishnanagar (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Falakata (west bengal) to Kolkata. Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Farakka. Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Dhupguri (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Falakata (west bengal) to Malda. Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Gazole. Extracting available data.\n",
      "'View Buses' button not found for route Berhampore (West Bengal) to Falakata (west bengal). Extracting available data.\n",
      "'View Buses' button not found for route Balurghat to Siliguri. Extracting available data.\n",
      "'View Buses' button not found for route Siliguri to Barasat (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Maynaguri (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Kolkata to Itahar (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Cooch Behar (West Bengal) to Omarpur (West Bengal). Extracting available data.\n",
      "'View Buses' button not found for route Berhampore (West Bengal) to Jalpaiguri. Extracting available data.\n",
      "'View Buses' button not found for route Malda to Siliguri. Extracting available data.\n",
      "'View Buses' button not found for route Raiganj to Ranaghat. Extracting available data.\n",
      "'View Buses' button not found for route Cooch Behar (West Bengal) to Farakka. Extracting available data.\n",
      "'View Buses' button not found for route Cooch Behar (West Bengal) to Siliguri. Extracting available data.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the URL in the browser\n",
    "driver.get('https://www.redbus.in/online-booking/north-bengal-state-transport-corporation')\n",
    "# URL for scraping the government bus data. Paste the link as per other government bus services to scrape.\n",
    "driver.maximize_window()\n",
    "time.sleep(10)\n",
    "\n",
    "# Function to extract routes from the current page\n",
    "def extract_routes():\n",
    "    elements = driver.find_elements(By.XPATH, \"//a[@class='route']\")\n",
    "    return [{'text': element.text, 'link': element.get_attribute('href')} for element in elements]\n",
    "\n",
    "# Initialize routes list\n",
    "all_routes = []\n",
    "\n",
    "# Try to navigate through pages and capture routes\n",
    "page_xpaths = [\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[2]',  # Page 2\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[3]',  # Page 3\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[4]',  # Page 4\n",
    "    '//*[@id=\"root\"]/div/div[4]/div[12]/div[5]'   # Page 5\n",
    "]\n",
    "\n",
    "# Extract routes from the first page\n",
    "all_routes.extend(extract_routes())\n",
    "\n",
    "# Loop through each page's XPath and extract routes\n",
    "for page_xpath in page_xpaths:\n",
    "    try:\n",
    "        # Wait for the element to be clickable\n",
    "        element = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, page_xpath)))\n",
    "\n",
    "        # Scroll the element into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Click the element using JavaScript\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Extract routes from the current page\n",
    "        all_routes.extend(extract_routes())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not navigate to the next page or extract routes: {e}\")\n",
    "        continue\n",
    "\n",
    "# Prepare the CSV file\n",
    "csv_file_path = 'NBSTC_bus_data.csv'\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Route Name', 'Route Link', 'Bus Name', 'Bus Type', 'Departing Time', 'Duration', 'Reaching Time', 'Star Rating', 'Price', 'Seats Available'])\n",
    "\n",
    "    for route in all_routes:\n",
    "        # Navigate to the route page\n",
    "        driver.get(route['link'])\n",
    "        time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            # Attempt to click on the \"View Buses\" element if it exists\n",
    "            view_buses_xpath = '//*[@id=\"result-section\"]/div[1]/div/div[2]/div/div[4]/div[2]'\n",
    "            view_buses = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, view_buses_xpath)))\n",
    "            view_buses.click()\n",
    "            time.sleep(5)\n",
    "        except TimeoutException:\n",
    "            print(f\"'View Buses' button not found for route {route['text']}. Extracting available data.\")\n",
    "\n",
    "        # Scroll down to the bottom of the page to load all content\n",
    "        SCROLL_PAUSE_TIME = 5\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            # Scroll down to the bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            \n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Extract data after reaching the bottom of the page\n",
    "        def get_elements(xpath):\n",
    "            return [elem.text for elem in driver.find_elements(By.XPATH, xpath)]\n",
    "\n",
    "        busname_xpath = \"//div[@class='travels lh-24 f-bold d-color']\"\n",
    "        bustype_xpath = \"//*[@class='bus-type f-12 m-top-16 l-color evBus']\"\n",
    "        departing_time_xpath = \"//*[@class='dp-time f-19 d-color f-bold']\"\n",
    "        duration_xpath = \"//*[@class='dur l-color lh-24']\"\n",
    "        reaching_time_xpath = \"//*[@class='bp-time f-19 d-color disp-Inline']\"\n",
    "        star_rating_xpath = \"//*[@class='column-six p-right-10 w-10 fl']\"\n",
    "        price_xpath = \"//*[contains(@class, 'fare d-block')]\"\n",
    "        seats_available_xpath = \"//*[@class='column-eight w-15 fl']\"\n",
    "\n",
    "        busnames = get_elements(busname_xpath)\n",
    "        bustypes = get_elements(bustype_xpath)\n",
    "        departing_times = get_elements(departing_time_xpath)\n",
    "        durations = get_elements(duration_xpath)\n",
    "        reaching_times = get_elements(reaching_time_xpath)\n",
    "        star_ratings = get_elements(star_rating_xpath)\n",
    "        prices = get_elements(price_xpath)\n",
    "        seats_available = get_elements(seats_available_xpath)\n",
    "\n",
    "        # Define the clean_price function\n",
    "        def clean_price(price_text):\n",
    "            return re.sub(r'[^0-9.]', '', price_text.strip())\n",
    "\n",
    "        # Clean and extend lists\n",
    "        prices = [clean_price(price) for price in prices]\n",
    "\n",
    "        length = max(len(busnames), len(bustypes), len(departing_times), len(durations), len(reaching_times), len(star_ratings), len(prices), len(seats_available))\n",
    "\n",
    "        def extend_list(lst, length):\n",
    "            return lst + ['N/A'] * (length - len(lst))\n",
    "\n",
    "        busnames = extend_list(busnames, length)\n",
    "        bustypes = extend_list(bustypes, length)\n",
    "        departing_times = extend_list(departing_times, length)\n",
    "        durations = extend_list(durations, length)\n",
    "        reaching_times = extend_list(reaching_times, length)\n",
    "        star_ratings = extend_list(star_ratings, length)\n",
    "        prices = extend_list(prices, length)\n",
    "        seats_available = extend_list(seats_available, length)\n",
    "\n",
    "        # Write data to CSV\n",
    "        for i in range(length):\n",
    "            writer.writerow([\n",
    "                route['text'],\n",
    "                route['link'],\n",
    "                busnames[i],\n",
    "                bustypes[i],\n",
    "                departing_times[i],\n",
    "                durations[i],\n",
    "                reaching_times[i],\n",
    "                star_ratings[i],\n",
    "                prices[i],\n",
    "                seats_available[i]\n",
    "            ])\n",
    "\n",
    "        # Go back to the main route list\n",
    "        driver.back()\n",
    "        time.sleep(10) \n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c1345-a8c6-44f1-985e-52d6b817aa76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
